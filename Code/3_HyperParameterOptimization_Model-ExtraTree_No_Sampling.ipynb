{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Import Essential Data handling libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from math import floor\n",
    "from time import perf_counter\n",
    "\n",
    "import matplotlib.pyplot as plt,seaborn as sns\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing Machine Learning Libraries and functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, auc, f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from skopt import space\n",
    "from skopt import gp_minimize\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"..\\data\\creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-1.360</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>2.536</td>\n",
       "      <td>1.378</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.552</td>\n",
       "      <td>-0.618</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>1.468</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.251</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.278</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>149.620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.192</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>1.613</td>\n",
       "      <td>1.065</td>\n",
       "      <td>0.489</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.464</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.639</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.015</td>\n",
       "      <td>2.690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.358</td>\n",
       "      <td>-1.340</td>\n",
       "      <td>1.773</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>1.800</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.248</td>\n",
       "      <td>-1.515</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.717</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>2.346</td>\n",
       "      <td>-2.890</td>\n",
       "      <td>1.110</td>\n",
       "      <td>-0.121</td>\n",
       "      <td>-2.262</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.909</td>\n",
       "      <td>-0.689</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>378.660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>1.793</td>\n",
       "      <td>-0.863</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>1.247</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-1.387</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.508</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>-1.060</td>\n",
       "      <td>-0.684</td>\n",
       "      <td>1.966</td>\n",
       "      <td>-1.233</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-1.176</td>\n",
       "      <td>0.647</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.061</td>\n",
       "      <td>123.500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.000</td>\n",
       "      <td>-1.158</td>\n",
       "      <td>0.878</td>\n",
       "      <td>1.549</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.593</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.753</td>\n",
       "      <td>-0.823</td>\n",
       "      <td>0.538</td>\n",
       "      <td>1.346</td>\n",
       "      <td>-1.120</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.409</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.798</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.215</td>\n",
       "      <td>69.990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time     V1     V2    V3     V4     V5     V6     V7     V8     V9    V10  \\\n",
       "0 0.000 -1.360 -0.073 2.536  1.378 -0.338  0.462  0.240  0.099  0.364  0.091   \n",
       "1 0.000  1.192  0.266 0.166  0.448  0.060 -0.082 -0.079  0.085 -0.255 -0.167   \n",
       "2 1.000 -1.358 -1.340 1.773  0.380 -0.503  1.800  0.791  0.248 -1.515  0.208   \n",
       "3 1.000 -0.966 -0.185 1.793 -0.863 -0.010  1.247  0.238  0.377 -1.387 -0.055   \n",
       "4 2.000 -1.158  0.878 1.549  0.403 -0.407  0.096  0.593 -0.271  0.818  0.753   \n",
       "\n",
       "     V11    V12    V13    V14    V15    V16    V17    V18    V19    V20  \\\n",
       "0 -0.552 -0.618 -0.991 -0.311  1.468 -0.470  0.208  0.026  0.404  0.251   \n",
       "1  1.613  1.065  0.489 -0.144  0.636  0.464 -0.115 -0.183 -0.146 -0.069   \n",
       "2  0.625  0.066  0.717 -0.166  2.346 -2.890  1.110 -0.121 -2.262  0.525   \n",
       "3 -0.226  0.178  0.508 -0.288 -0.631 -1.060 -0.684  1.966 -1.233 -0.208   \n",
       "4 -0.823  0.538  1.346 -1.120  0.175 -0.451 -0.237 -0.038  0.803  0.409   \n",
       "\n",
       "     V21    V22    V23    V24    V25    V26    V27    V28  Amount  Class  \n",
       "0 -0.018  0.278 -0.110  0.067  0.129 -0.189  0.134 -0.021 149.620      0  \n",
       "1 -0.226 -0.639  0.101 -0.340  0.167  0.126 -0.009  0.015   2.690      0  \n",
       "2  0.248  0.772  0.909 -0.689 -0.328 -0.139 -0.055 -0.060 378.660      0  \n",
       "3 -0.108  0.005 -0.190 -1.176  0.647 -0.222  0.063  0.061 123.500      0  \n",
       "4 -0.009  0.798 -0.137  0.141 -0.206  0.502  0.219  0.215  69.990      0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.drop([\"Time\"], axis = 1, inplace  = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n",
      "\n",
      " % distribution\n",
      " 0   99.827\n",
      "1    0.173\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_raw.Class.value_counts())\n",
    "\n",
    "print(\"\\n\",\"% distribution\\n\",df_raw.Class.value_counts(True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUPRC(y_true, y_pred_proba) :\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true = y_true, probas_pred= y_pred_proba)\n",
    "    auprc = auc(recall, precision)\n",
    "    return(np.round(auprc, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Transformation\n",
    "* 1. Quantile Transformation (normal distribution)\n",
    "* 2. standard scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_transformer = QuantileTransformer(output_distribution=\"normal\")\n",
    "standard_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = df_raw.copy()\n",
    "\n",
    "for i in range(df_transformed.iloc[:,:-1].shape[1]):\n",
    "    qt_transformed_var = quantile_transformer.fit_transform(df_transformed.iloc[:,i].values.reshape(-1,1))[:,0]\n",
    "    qt_transformed_std_scaled = standard_scaler.fit_transform(qt_transformed_var.reshape(-1,1))[:,0]\n",
    "    \n",
    "    df_transformed.iloc[:,i] = qt_transformed_std_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>2.132</td>\n",
       "      <td>1.191</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.307</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-0.885</td>\n",
       "      <td>-1.001</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>1.771</td>\n",
       "      <td>-0.677</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.196</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>0.836</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>1.030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.459</td>\n",
       "      <td>0.216</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.217</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>0.164</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>1.637</td>\n",
       "      <td>1.359</td>\n",
       "      <td>0.509</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.582</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.664</td>\n",
       "      <td>-0.837</td>\n",
       "      <td>0.491</td>\n",
       "      <td>-0.650</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.389</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.998</td>\n",
       "      <td>-1.270</td>\n",
       "      <td>1.382</td>\n",
       "      <td>0.344</td>\n",
       "      <td>-0.486</td>\n",
       "      <td>1.374</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-1.456</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.571</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.730</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>2.777</td>\n",
       "      <td>-2.673</td>\n",
       "      <td>1.488</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-2.491</td>\n",
       "      <td>1.379</td>\n",
       "      <td>0.886</td>\n",
       "      <td>1.036</td>\n",
       "      <td>2.020</td>\n",
       "      <td>-1.121</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>-0.766</td>\n",
       "      <td>1.596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.718</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>1.400</td>\n",
       "      <td>-0.689</td>\n",
       "      <td>0.047</td>\n",
       "      <td>1.185</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.760</td>\n",
       "      <td>-1.359</td>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.528</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>-0.722</td>\n",
       "      <td>-1.282</td>\n",
       "      <td>-1.049</td>\n",
       "      <td>2.194</td>\n",
       "      <td>-1.520</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.791</td>\n",
       "      <td>-1.675</td>\n",
       "      <td>1.393</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.160</td>\n",
       "      <td>0.368</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.704</td>\n",
       "      <td>-0.855</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.953</td>\n",
       "      <td>-0.741</td>\n",
       "      <td>0.556</td>\n",
       "      <td>1.387</td>\n",
       "      <td>-1.385</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>1.105</td>\n",
       "      <td>1.237</td>\n",
       "      <td>0.064</td>\n",
       "      <td>1.082</td>\n",
       "      <td>-0.575</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>1.024</td>\n",
       "      <td>1.071</td>\n",
       "      <td>1.454</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      V1     V2     V3     V4     V5    V6     V7     V8     V9    V10    V11  \\\n",
       "0 -0.999 -0.158  2.132  1.191 -0.304 0.725  0.287  0.200  0.438  0.307 -0.465   \n",
       "1  0.459  0.216 -0.007  0.417  0.122 0.217 -0.160  0.164 -0.249 -0.117  1.637   \n",
       "2 -0.998 -1.270  1.382  0.344 -0.486 1.374  0.962  0.536 -1.456  0.450  0.571   \n",
       "3 -0.718 -0.285  1.400 -0.689  0.047 1.185  0.284  0.760 -1.359  0.062 -0.171   \n",
       "4 -0.861  0.750  1.160  0.368 -0.381 0.404  0.704 -0.855  0.864  0.953 -0.741   \n",
       "\n",
       "     V12    V13    V14    V15    V16    V17    V18    V19    V20    V21  \\\n",
       "0 -0.885 -1.001 -0.519  1.771 -0.677  0.399  0.043  0.598  0.966  0.036   \n",
       "1  1.359  0.509 -0.287  0.664  0.582 -0.071 -0.250 -0.224 -0.027 -0.664   \n",
       "2 -0.095  0.730 -0.318  2.777 -2.673  1.488 -0.162 -2.491  1.379  0.886   \n",
       "3  0.050  0.528 -0.487 -0.722 -1.282 -1.049  2.194 -1.520 -0.657 -0.263   \n",
       "4  0.556  1.387 -1.385  0.145 -0.653 -0.254 -0.045  1.105  1.237  0.064   \n",
       "\n",
       "     V22    V23    V24    V25    V26    V27    V28  Amount  Class  \n",
       "0  0.350 -0.459  0.079  0.196 -0.308  0.836 -0.320   1.030      0  \n",
       "1 -0.837  0.491 -0.650  0.270  0.389 -0.094  0.055  -0.838      0  \n",
       "2  1.036  2.020 -1.121 -0.697 -0.193 -0.535 -0.766   1.596      0  \n",
       "3 -0.003 -0.791 -1.675  1.393 -0.393  0.521  0.569   0.925      0  \n",
       "4  1.082 -0.575  0.224 -0.407  1.024  1.071  1.454   0.597      0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected vars (manual feature selection)\n",
    "all_vars = list(set(list(df_transformed.columns)) - set([\"V8\",\"V13\",\"V15\", \"V19\", \"V20\", \"V22\", \"V23\",\"V24\", \"V25\", \"V26\", \"Amount\"]))\n",
    " \n",
    "df = df_transformed[all_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V4</th>\n",
       "      <th>V12</th>\n",
       "      <th>V7</th>\n",
       "      <th>V18</th>\n",
       "      <th>V2</th>\n",
       "      <th>V14</th>\n",
       "      <th>V5</th>\n",
       "      <th>V9</th>\n",
       "      <th>V27</th>\n",
       "      <th>V16</th>\n",
       "      <th>V1</th>\n",
       "      <th>V3</th>\n",
       "      <th>V21</th>\n",
       "      <th>V11</th>\n",
       "      <th>Class</th>\n",
       "      <th>V17</th>\n",
       "      <th>V6</th>\n",
       "      <th>V10</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.191</td>\n",
       "      <td>-0.885</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.836</td>\n",
       "      <td>-0.677</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>2.132</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.307</td>\n",
       "      <td>-0.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.417</td>\n",
       "      <td>1.359</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>0.216</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.459</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.664</td>\n",
       "      <td>1.637</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.217</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.344</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.962</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-1.270</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>-0.486</td>\n",
       "      <td>-1.456</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>-2.673</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>1.382</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0</td>\n",
       "      <td>1.488</td>\n",
       "      <td>1.374</td>\n",
       "      <td>0.450</td>\n",
       "      <td>-0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.689</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.284</td>\n",
       "      <td>2.194</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-1.359</td>\n",
       "      <td>0.521</td>\n",
       "      <td>-1.282</td>\n",
       "      <td>-0.718</td>\n",
       "      <td>1.400</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.049</td>\n",
       "      <td>1.185</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.368</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.704</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.750</td>\n",
       "      <td>-1.385</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1.071</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>1.160</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.741</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.953</td>\n",
       "      <td>1.454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      V4    V12     V7    V18     V2    V14     V5     V9    V27    V16  \\\n",
       "0  1.191 -0.885  0.287  0.043 -0.158 -0.519 -0.304  0.438  0.836 -0.677   \n",
       "1  0.417  1.359 -0.160 -0.250  0.216 -0.287  0.122 -0.249 -0.094  0.582   \n",
       "2  0.344 -0.095  0.962 -0.162 -1.270 -0.318 -0.486 -1.456 -0.535 -2.673   \n",
       "3 -0.689  0.050  0.284  2.194 -0.285 -0.487  0.047 -1.359  0.521 -1.282   \n",
       "4  0.368  0.556  0.704 -0.045  0.750 -1.385 -0.381  0.864  1.071 -0.653   \n",
       "\n",
       "      V1     V3    V21    V11  Class    V17    V6    V10    V28  \n",
       "0 -0.999  2.132  0.036 -0.465      0  0.399 0.725  0.307 -0.320  \n",
       "1  0.459 -0.007 -0.664  1.637      0 -0.071 0.217 -0.117  0.055  \n",
       "2 -0.998  1.382  0.886  0.571      0  1.488 1.374  0.450 -0.766  \n",
       "3 -0.718  1.400 -0.263 -0.171      0 -1.049 1.185  0.062  0.569  \n",
       "4 -0.861  1.160  0.064 -0.741      0 -0.254 0.404  0.953  1.454  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HyperParameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Scoring function\n",
    "def AUPRC(y_true, y_pred_proba) :\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true = y_true, probas_pred= y_pred_proba)\n",
    "    auprc = auc(recall, precision)\n",
    "    return(np.round(auprc, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(params, x, y):\n",
    "    model = ExtraTreesClassifier(**params)\n",
    "    kf = model_selection.StratifiedKFold(n_splits = 5)\n",
    "    auprc = []\n",
    "    for idx in kf.split(X = x, y = y):\n",
    "        train_idx, test_idx = idx[0], idx[1]\n",
    "        xtrain = x[train_idx]\n",
    "        ytrain = y[train_idx]\n",
    "        \n",
    "        xtest = x[test_idx]\n",
    "        ytest = y[test_idx]\n",
    "        \n",
    "        model.fit(xtrain, ytrain)\n",
    "        pred_proba = model.predict_proba(xtest)[:, 1]\n",
    "        fold_auprc = AUPRC(ytest, pred_proba)\n",
    "        \n",
    "        auprc.append(fold_auprc)\n",
    "    \n",
    "    return -1.0*np.round(np.mean(auprc),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 20/20 [34:44<00:00, 104.22s/trial, best loss: -0.7753]\n",
      "{'criterion': 0, 'max_depth': 4, 'max_features': 1, 'min_samples_leaf': 1, 'min_samples_split': 0, 'n_estimators': 0, 'n_jobs': 0}\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"Class\", axis = 1).values\n",
    "y = df.Class.values\n",
    "\n",
    "param_space for ExtraTree\n",
    "param_space = { \n",
    "    \"n_estimators\" : hp.choice(\"n_estimators\", [100,150,200,250,300]),\n",
    "    \"max_depth\" : hp.choice(\"max_depth\", [3,5,7,9,11]),\n",
    "    \"criterion\" : hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "    \"min_samples_split\" : hp.choice(\"min_samples_split\", [2,4,6,8]),\n",
    "    \"min_samples_leaf\": hp.choice(\"min_samples_leaf\", [3,4,5]),\n",
    "    \"max_features\": hp.choice(\"max_features\", [4,5,6,7]),\n",
    "    \"n_jobs\" : hp.choice(\"n_jobs\", [-1])\n",
    "}\n",
    "\n",
    "\n",
    "optimization_function = partial(optimize, x = X, y = y)\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "result = fmin(\n",
    "    algo = tpe.suggest,\n",
    "    fn = optimization_function,\n",
    "    space = param_space, \n",
    "    max_evals = 20,\n",
    "    trials = trials\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Fitting on the above hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Area Under Precision Recall Curve =  0.84\n",
      "Average F1 score =  0.83\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier(max_depth=11, max_features=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100, n_jobs = -1)\n",
    "# model = ExtraTreesClassifier()\n",
    "\n",
    "def create_stratified_folds(data, k_fold_num, target_variable):\n",
    "    data[\"kfold\"] = -1 # we create a new column called kfold and fill it with -1\n",
    "    data = data.sample(frac=1).reset_index(drop=True) # the next step is to randomize the rows of the data\n",
    "\n",
    "    y = data[target_variable].values\n",
    "\n",
    "    kf = model_selection.StratifiedKFold(n_splits= k_fold_num)\n",
    "\n",
    "    for fold, (trn_, partitioned_idx_) in enumerate(kf.split(X=data, y = y)):\n",
    "        data.loc[partitioned_idx_, 'kfold'] = fold\n",
    "    return(data)\n",
    "\n",
    "# Creating stratified k-fold within the data\n",
    "k_fold_num = 5\n",
    "\n",
    "df = create_stratified_folds(df, k_fold_num = 5, target_variable = \"Class\")\n",
    "\n",
    "features = [f for f in df.columns if f not in [\"kfold\",\"Class\"]]\n",
    "\n",
    "cv_auprc = []\n",
    "f1_scores = []\n",
    "for fold in range(k_fold_num):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    x_train = df_train[features].values\n",
    "    x_valid = df_valid[features].values\n",
    "\n",
    "    model.fit(x_train, df_train.Class.values)\n",
    "\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    valid_preds_binary = model.predict(x_valid)\n",
    "\n",
    "    auprc = AUPRC(df_valid.Class.values, valid_preds)\n",
    "    f1 = f1_score(df_valid.Class.values, valid_preds_binary)\n",
    "\n",
    "    cv_auprc.append(auprc)\n",
    "    f1_scores.append(np.round(f1,4))\n",
    "\n",
    "print(\"Average Area Under Precision Recall Curve = \", np.round(np.mean(cv_auprc),2))\n",
    "print(\"Average F1 score = \", np.round(np.mean(f1_scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.777, 0.8445, 0.8665, 0.8526, 0.845]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7684, 0.8444, 0.8556, 0.8495, 0.8449]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with default hyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Area Under Precision Recall Curve =  0.85\n",
      "Average F1 score =  0.86\n"
     ]
    }
   ],
   "source": [
    "# model = ExtraTreesClassifier(max_depth=11, max_features=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100, n_jobs = -1)\n",
    "model = ExtraTreesClassifier()\n",
    "\n",
    "def create_stratified_folds(data, k_fold_num, target_variable):\n",
    "    data[\"kfold\"] = -1 # we create a new column called kfold and fill it with -1\n",
    "    data = data.sample(frac=1).reset_index(drop=True) # the next step is to randomize the rows of the data\n",
    "\n",
    "    y = data[target_variable].values\n",
    "\n",
    "    kf = model_selection.StratifiedKFold(n_splits= k_fold_num)\n",
    "\n",
    "    for fold, (trn_, partitioned_idx_) in enumerate(kf.split(X=data, y = y)):\n",
    "        data.loc[partitioned_idx_, 'kfold'] = fold\n",
    "    return(data)\n",
    "\n",
    "# Creating stratified k-fold within the data\n",
    "k_fold_num = 5\n",
    "\n",
    "df = create_stratified_folds(df, k_fold_num = 5, target_variable = \"Class\")\n",
    "\n",
    "features = [f for f in df.columns if f not in [\"kfold\",\"Class\"]]\n",
    "\n",
    "cv_auprc = []\n",
    "f1_scores = []\n",
    "for fold in range(k_fold_num):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    x_train = df_train[features].values\n",
    "    x_valid = df_valid[features].values\n",
    "\n",
    "    model.fit(x_train, df_train.Class.values)\n",
    "\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    valid_preds_binary = model.predict(x_valid)\n",
    "\n",
    "    auprc = AUPRC(df_valid.Class.values, valid_preds)\n",
    "    f1 = f1_score(df_valid.Class.values, valid_preds_binary)\n",
    "\n",
    "    cv_auprc.append(auprc)\n",
    "    f1_scores.append(np.round(f1,4))\n",
    "\n",
    "print(\"Average Area Under Precision Recall Curve = \", np.round(np.mean(cv_auprc),2))\n",
    "print(\"Average F1 score = \", np.round(np.mean(f1_scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8389, 0.8634, 0.8349, 0.8636, 0.8734]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8539, 0.8889, 0.8492, 0.8743, 0.8539]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(trial, x, y):\n",
    "    \n",
    "    model = ExtraTreesClassifier(**params)\n",
    "    kf = model_selection.StratifiedKFold(n_splits = 5)\n",
    "    auprc = []\n",
    "    for idx in kf.split(X = x, y = y):\n",
    "        train_idx, test_idx = idx[0], idx[1]\n",
    "        xtrain = x[train_idx]\n",
    "        ytrain = y[train_idx]\n",
    "        \n",
    "        xtest = x[test_idx]\n",
    "        ytest = y[test_idx]\n",
    "        \n",
    "        model.fit(xtrain, ytrain)\n",
    "        pred_proba = model.predict_proba(xtest)[:, 1]\n",
    "        fold_auprc = AUPRC(ytest, pred_proba)\n",
    "        \n",
    "        auprc.append(fold_auprc)\n",
    "    \n",
    "    return -1.0*np.round(np.mean(auprc),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 20/20 [34:44<00:00, 104.22s/trial, best loss: -0.7753]\n",
      "{'criterion': 0, 'max_depth': 4, 'max_features': 1, 'min_samples_leaf': 1, 'min_samples_split': 0, 'n_estimators': 0, 'n_jobs': 0}\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"Class\", axis = 1).values\n",
    "y = df.Class.values\n",
    "\n",
    "# param_space for ExtraTree\n",
    "param_space = { \n",
    "    \"n_estimators\" : hp.choice(\"n_estimators\", [100,150,200,250,300]),\n",
    "    \"max_depth\" : hp.choice(\"max_depth\", [3,5,7,9,11]),\n",
    "    \"criterion\" : hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "    \"min_samples_split\" : hp.choice(\"min_samples_split\", [2,4,6,8]),\n",
    "    \"min_samples_leaf\": hp.choice(\"min_samples_leaf\", [3,4,5]),\n",
    "    \"max_features\": hp.choice(\"max_features\", [4,5,6,7])\n",
    "}\n",
    "\n",
    "\n",
    "optimization_function = partial(optimize, x = X, y = y)\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "result = fmin(\n",
    "    algo = tpe.suggest,\n",
    "    fn = optimization_function,\n",
    "    space = param_space, \n",
    "    max_evals = 20,\n",
    "    trials = trials\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Fitting on the above hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesClassifier(max_depth=11, max_features=5, min_samples_leaf=4, min_samples_split=2, n_estimators=100, n_jobs = -1)\n",
    "# model = ExtraTreesClassifier()\n",
    "\n",
    "def create_stratified_folds(data, k_fold_num, target_variable):\n",
    "    data[\"kfold\"] = -1 # we create a new column called kfold and fill it with -1\n",
    "    data = data.sample(frac=1).reset_index(drop=True) # the next step is to randomize the rows of the data\n",
    "\n",
    "    y = data[target_variable].values\n",
    "\n",
    "    kf = model_selection.StratifiedKFold(n_splits= k_fold_num)\n",
    "\n",
    "    for fold, (trn_, partitioned_idx_) in enumerate(kf.split(X=data, y = y)):\n",
    "        data.loc[partitioned_idx_, 'kfold'] = fold\n",
    "    return(data)\n",
    "\n",
    "# Creating stratified k-fold within the data\n",
    "k_fold_num = 5\n",
    "\n",
    "df = create_stratified_folds(df, k_fold_num = 5, target_variable = \"Class\")\n",
    "\n",
    "features = [f for f in df.columns if f not in [\"kfold\",\"Class\"]]\n",
    "\n",
    "cv_auprc = []\n",
    "f1_scores = []\n",
    "for fold in range(k_fold_num):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    x_train = df_train[features].values\n",
    "    x_valid = df_valid[features].values\n",
    "\n",
    "    model.fit(x_train, df_train.Class.values)\n",
    "\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    valid_preds_binary = model.predict(x_valid)\n",
    "\n",
    "    auprc = AUPRC(df_valid.Class.values, valid_preds)\n",
    "    f1 = f1_score(df_valid.Class.values, valid_preds_binary)\n",
    "\n",
    "    cv_auprc.append(auprc)\n",
    "    f1_scores.append(np.round(f1,4))\n",
    "\n",
    "print(\"Average Area Under Precision Recall Curve = \", np.round(np.mean(cv_auprc),2))\n",
    "print(\"Average F1 score = \", np.round(np.mean(f1_scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
